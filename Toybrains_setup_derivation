# Toybrains simulation dataset 
$\color{BrickRed}\text{Analysis timeline: July 2024 - Nov 2024}$

## Introduction :
* Toybrains is a synthetic dataset of 2D images that can be used to experiment with different machine learning (ML) models and understand what concepts they learn under different causal generative mechanisms.
* Latents: The images are generated by 16 image generation variables or 'latents' (refer [fig 1(a)](#fig1) and the [Toybrains ReadMe](https://github.com/RoshanRane/toybrains/blob/main/docs/toybrains.png) for more details). Each latent is treated as a multinomial random variable with an associated proba.dist (probabilty distribution) that can be modified by other external variables or 'concepts'.
* Concepts: Additionally, users can define any number of random variables or 'concept' that can influence the proba.dist of latents or each others. Each concept variable also has an associated proba.dist that can be modified by other concepts. In a ML experiment with a model $f_{\theta} : X \Rightarrow y$, the concepts can be labels $y$ or the mediators and confounders that drive the relationship $X y$ See the demonstration in [fig 1(b)](#fig1). How different concepts influence the proba.dist of the latents and other concepts are defined by a generative causal graph (a Python dictionary).
![Figure1](https://github.com/RoshanRane/toybrains/blob/main/docs/toybrains_illustration.png)_Figure 1: Data generation process of Toybrains._
* Test datasets: The Toybrains dataset allows users to validate ML models $f_{\theta} : X \Rightarrow y$ by determining if it learns the correct concepts influence the relationship between the images $X$ and the label $y$ in the dataset. It can be used to understand how different causal pathways (such as confounders $X \leftarrow c_k \rightarrow y$ and mediators $X \rightarrow c_k \rightarrow y$) can effect prediction performance. This is achieved by validation the ML models on counterfactual test datasets generated by Toybrains. For every concept configured in the dataset, Toybrains generates a counterfactual test(b)  dataset where the effects of the concept is disabled by disabling all its edges in the generative graph. 

## Derivation: how to use counterfactual test datasets to quantify true concept effects
Notation: If $S$ is a set then subscripted $S_i$ implies the $i^{th}$ sample of the set $S$ and a superscript $S^a$ is a subset of $S$ having a group of samples. Generative causal links are represented as $\overset{\beta}\leftarrow$ and $\overset{\gamma}\rightarrow$, but a model transformation is represented by $f_{\theta}:\Rightarrow$.

### Definitions
A Toybrains dataset $\mathcal{D}$ consists of 3 features 
* (a) $n_{obs}$ datapoints described by 4 components $[X,y,L,C]$
* (b) The generative graph $\mathbb{G}$
* (c) Counterfactual test datasets $\mathcal{D}^{test-c_k}$.

#### (a) Each datapoint $\mathcal{D}_i$ is has 4 components $[X,y,L,C]$:
1. $X \in \mathbb{R}^{64\times64}$ is the input 2D image.
2. $L  =[l_1, l_2, \ldots ,l_{16}],   \forall l_i \in \mathbb{R} \lor l_i \in \mathbb{Z}_n$ are the latent generative variables used that define the generate the image $X$. The 16 latents $L$ define different parts of the Toybrain such as the volume & color of the different shapes, the brightness of the whole brain shape, and so on. For more details refer to the [Toybrains ReadMe](https://github.com/RoshanRane/toybrains/blob/main/docs/toybrains.png).
3. $y \in \mathbb{Z}_2$ is the output label.
4. $C  =[c_1, c_2, \ldots ,c_{100}] ,   \forall c_k \in \mathbb{R} \lor c_k \in \mathbb{Z}_2 \lor c_k \in \mathbb{Z}_n$ are other covariates with mixed datatypes that influence the data generation process.

Variable in $[L,y,C]$ have an associated proba.dist that is by default a uniform distribution. 

#### (b) The data generation process is defined by a generative graph $\mathbb{G}$:
The probability dist. of variables $[L,y,C]$ can be changed by other variables in $[L,y,C]$. These relationships are defined by the graph $\mathbb{G}$. 
Currently, $\mathbb{G}$ can have 3 types of such relationships:
1. Covariate $c_k$ can influence latents with an effect size $\alpha_k$ :
   - $C^l = [c_k \in C \mid c_k \overset{\alpha_k}\rightarrow l_j]$
3. Latents $l_j$ can influence the output label with an effect size $\beta_j$ :
   - $L^y = [l_j \in L \mid l_j \overset{\beta_j}\rightarrow y]$
   - For simplicity, we set $|L^y|=1$
4. Covariates $c_k$ can influence the output label with an effect size $\gamma_k$ : 
   - $C^y = [c_k \in C \mid c_k \overset{\gamma_k}\rightarrow y]$

Confounders are covariates that influence both a latent and the output label are called : $C^{\text{con}} = [c_k \in C^l \cap C^y \mid l_j \overset{\alpha_k}\leftarrow c_k \overset{\gamma_k}\rightarrow y]$
   - Let $C^{\text{con}} = [\text{con}_1, \text{con}_2, \ldots ,\text{con}_m]$

Therefore, $\mathbb{G} = [ c_k \overset{\alpha_k}\rightarrow l_s] \cup [l_j \overset{\beta_j}\rightarrow y] \cup [c_i \overset{\gamma_i}\rightarrow y]$  $\forall c_k \in C^l$ and  $\forall l_y \in L^y  \land \forall c_i \in C^y$.

#### (c) Training and Test datasets: 
A dataset $\mathcal{D}$ consists of one training and several test datasplits $[\mathcal{D}^{\text{train}}, \mathcal{D}^{\text{test}}, \mathcal{D}^{\text {true}}, \mathcal{D}^{\text {con}_0}, \ldots \mathcal{D}^{\text {con}_m}, \mathcal{D}^{\text{null}}]$.

1. $\mathcal{D}^{\text{train}}$ is the training dataset sampled ($n_{obs} = 5000$) after applying all relationships in $\mathbb{G}$.
2. One test dataset $\mathcal{D}^{\text{test}}$ ($n_{obs} = 500$) sampled after applying $\mathbb{G}$.
3. One 'only-true' OOD test dataset $\mathcal{D}^{\text {true}}$ ($n_{obs} = 500$) sampled after applying only the edge $[l_j \overset{\beta_j}\rightarrow y]$ from $\mathbb{G}$. That is, all $\gamma_k = 0$ and all $\alpha_k = 0$ in $\mathbb{G}$.
4. $m$ 'only-conf' OOD test datasets $\mathcal{D}^{con_i}$ ($n_{obs} = 500$) sampled after applying only the edges with $\text{con}_i$ from $\mathbb{G}$. That is, if $con_i = c_k$ then the edges  $l_j \overset{\alpha_k}\leftarrow c_k \overset{\gamma_k}\rightarrow y$ are applied and $\beta_j = 0$ $\forall j$, $\gamma_i = 0$ $\forall i \ne k$, and $\alpha_i =0$ $\forall i \ne k$.
5. One 'null' test dataset $\mathcal{D}^{\text{null}}$ ($n_{obs} = 500$) sampled with all edges disabled ($\beta_j = 0$, $\gamma_i = 0$, $\alpha_i =0$) in $\mathbb{G}$.

### **The mathematical question**: 
 $\color{BrickRed}\text{How to generate a counterfactual test dataset } \mathcal{D}^{test-c_k} \text{ such that they can measure the exact effect produced by the concept } c_k \text{ on the relationship between } X \text{ and } y$ ?

What does validating a model on the OOD test dataset capture?
Specifically we are asking whether, if we train a model (such as the deep learning models that will be later evaluated) on $\mathcal{D}^{\text{train}}$,
1. does the accuracy of the model on the 'only-true' counterfactual test dataset $\mathcal{D}^{\text {test-l_y}}$ capture $\beta$ ?
2. does the accuracy of the model on the 'only-conf' OOD test dataset $\mathcal{D}^{test-con_i}$ capture $\gamma_i$ ?
